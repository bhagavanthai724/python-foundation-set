{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVBMomGxMsyH9rq8WGu7v3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagavanthai724/python-foundation-set/blob/main/19_nist_ai_rmf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize NIST RMF core functions\n",
        "summary = {\n",
        "    \"GOVERN\": \"Set policy, roles, accountability, oversight.\",\n",
        "    \"MAP\": \"Understand system, data, context, stakeholders, risks.\",\n",
        "    \"MEASURE\": \"Define and compute metrics to evaluate behavior.\",\n",
        "    \"MANAGE\": \"Operate, remediate, monitor, and reduce risk.\"\n",
        "}\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "0SXMQDJZ0M61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map AI risks to correct NIST RMF functions\n",
        "risk_mapping = {\n",
        "    \"data_bias\": [\"MAP\", \"MEASURE\"],\n",
        "    \"model_drift\": [\"MEASURE\", \"MANAGE\"],\n",
        "    \"regulatory_non_compliance\": [\"GOVERN\", \"MANAGE\"]\n",
        "}\n",
        "print(risk_mapping)"
      ],
      "metadata": {
        "id": "h0XbwZo-0Mui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset-quality checklist as Python dict\n",
        "dataset_checklist = {\n",
        "    \"accuracy\": \"labels validated; correctness rate measured\",\n",
        "    \"completeness\": \"no missing critical fields\",\n",
        "    \"consistency\": \"consistent data types and formats\",\n",
        "    \"provenance\": \"source documented\",\n",
        "    \"freshness\": \"recent enough for use case\",\n",
        "    \"representativeness\": \"coverage across groups\",\n",
        "    \"label_quality\": \"inter-annotator agreement measured\",\n",
        "    \"noise_rate\": \"duplicate/corrupted entries flagged\",\n",
        "    \"bias_assessment\": \"disparate-impact metrics checked\",\n",
        "    \"documentation\": \"schema + sampling method included\"\n",
        "}\n",
        "print(dataset_checklist)"
      ],
      "metadata": {
        "id": "08LJUnWD0Mhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Systemic risk vs model risk (string evaluation)\n",
        "comparison = \"\"\"\n",
        "Systemic Risk: comes from broader ecosystem interactions, incentives, downstream use.\n",
        "Model Risk: comes from errors/bias inside a specific model.\n",
        "Systemic risk needs governance; model risk needs technical evaluation.\n",
        "\"\"\"\n",
        "print(comparison)"
      ],
      "metadata": {
        "id": "6cU357R-0MVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Governance artifacts before deployment\n",
        "artifacts = [\n",
        "    \"risk_register\",\n",
        "    \"model_card\",\n",
        "    \"data_provenance_report\",\n",
        "    \"privacy_assessment\",\n",
        "    \"harm_taxonomy_and_mitigation_plan\",\n",
        "    \"access_control_policy\",\n",
        "    \"monitoring_plan\",\n",
        "    \"regulatory_compliance_mapping\"\n",
        "]\n",
        "print(artifacts)"
      ],
      "metadata": {
        "id": "HK3RQF0z0MKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Risk register template\n",
        "risk_register = {\n",
        "    \"id\": None,\n",
        "    \"risk\": \"\",\n",
        "    \"likelihood\": \"\",\n",
        "    \"impact\": \"\",\n",
        "    \"owner\": \"\",\n",
        "    \"mitigation\": \"\",\n",
        "    \"status\": \"\",\n",
        "    \"detection_date\": None,\n",
        "    \"residual_risk\": None,\n",
        "    \"review_date\": None\n",
        "}\n",
        "print(risk_register)"
      ],
      "metadata": {
        "id": "tUPQ-Isb0L-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAP-phase reviewer questions\n",
        "map_questions = [\n",
        "    \"What data sources trained the model?\",\n",
        "    \"What is the intended use and prohibited uses?\",\n",
        "    \"Who are the stakeholders?\",\n",
        "    \"What is the data lineage?\",\n",
        "    \"What deployment constraints apply?\"\n",
        "]\n",
        "print(map_questions)"
      ],
      "metadata": {
        "id": "mUBRlqOh0Lxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contextual integrity + example where it fails\n",
        "contextual_integrity = {\n",
        "    \"definition\": \"Data use must match contextual norms and expectations.\",\n",
        "    \"failure_example\": \"Health data used by a chatbot appears in public forum responses.\"\n",
        "}\n",
        "print(contextual_integrity)"
      ],
      "metadata": {
        "id": "08Gjtm1Z0Lmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Markdown table comparing NIST RMF vs ISO 42001\n",
        "table = \"\"\"\n",
        "| Aspect | NIST AI RMF | ISO 42001 |\n",
        "|-------|--------------|-----------|\n",
        "| Purpose | Risk mgmt guidance | AI management system standard |\n",
        "| Scope | Lifecycle functions | Org-level governance |\n",
        "| Focus | Practical eval + metrics | Auditable processes |\n",
        "| Cert | No certification | Certification-oriented |\n",
        "| Artifacts | Metrics, dashboards | Policies, procedures |\n",
        "\"\"\"\n",
        "print(table)"
      ],
      "metadata": {
        "id": "Npp_NMbz0LbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Measurable indicators for trustworthiness\n",
        "trust_indicators = [\n",
        "    \"safety_violation_rate\",\n",
        "    \"expected_calibration_error\",\n",
        "    \"hallucination_rate\"\n",
        "]\n",
        "print(trust_indicators)"
      ],
      "metadata": {
        "id": "huolPoZT0LRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Incident categories aligned to MANAGE phase\n",
        "incident_categories = {\n",
        "    \"safety_incident\": \"Triggered when model outputs cause or risk harm.\",\n",
        "    \"security_privacy_incident\": \"Triggered on data exposure or unauthorized access.\"\n",
        "}\n",
        "print(incident_categories)"
      ],
      "metadata": {
        "id": "3btgthUE0KjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation pipeline role + three metrics\n",
        "measure_info = {\n",
        "    \"role\": \"Pipelines compute metrics and convert raw outputs into measurable signals.\",\n",
        "    \"metrics\": [\n",
        "        \"safety_violation_rate\",\n",
        "        \"drift_metric\",\n",
        "        \"refusal_precision_recall\"\n",
        "    ]\n",
        "}\n",
        "print(measure_info)"
      ],
      "metadata": {
        "id": "dfFwo-O60Kfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lightweight NIST-aligned mitigation workflow\n",
        "mitigation_workflow = [\n",
        "    \"identify_issue\",\n",
        "    \"assess_severity_and_root_cause\",\n",
        "    \"prioritize_in_risk_register\",\n",
        "    \"apply_mitigation\",\n",
        "    \"monitor_effectiveness\",\n",
        "    \"document_and_update_governance\"\n",
        "]\n",
        "print(mitigation_workflow)"
      ],
      "metadata": {
        "id": "rZittvOZ0KdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert NIST lifecycle into 6 analyst review steps\n",
        "review_steps = [\n",
        "    \"review_governance_and_intended_use\",\n",
        "    \"inventory_data_model_and_assets\",\n",
        "    \"define_metrics_and_tests\",\n",
        "    \"run_evaluation_pipelines\",\n",
        "    \"triage_and_mitigate_issues\",\n",
        "    \"report_findings_and_update_risk_docs\"\n",
        "]\n",
        "print(review_steps)"
      ],
      "metadata": {
        "id": "kiJ9MOBx0Kap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How Log Analyzer + Incident Detector fit MEASURE + MANAGE\n",
        "explanation = \"\"\"\n",
        "MEASURE: Log Analyzer extracts structured metrics (errors, violations, severities).\n",
        "MANAGE: Incident Detector triggers alerts, triage, and corrective actions.\n",
        "Together: They close the loop from detection → action → verification.\n",
        "\"\"\"\n",
        "print(explanation)"
      ],
      "metadata": {
        "id": "C1sJFgCN0KYH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}