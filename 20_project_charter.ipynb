{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVilcGrLn7gCCEvq0acqIG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhagavanthai724/python-foundation-set/blob/main/20_project_charter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE3NoQAMPRsb"
      },
      "outputs": [],
      "source": [
        "# Auto-generate a crisp, professional Project Charter for:\n",
        "# Major Project 1 â€” Log Analyzer + Incident Detector\n",
        "import json\n",
        "from pprint import pprint\n",
        "# -----------------------------------------\n",
        "# 1) Charter Components\n",
        "# -----------------------------------------\n",
        "goals = [\n",
        "    \"Develop a reliable Log Analyzer that extracts structured fields from raw logs.\",\n",
        "    \"Implement an Incident Detector that flags safety, security, and reliability events.\",\n",
        "    \"Enable regex-driven detection for ERROR, WARNING, CRITICAL, and security anomalies.\",\n",
        "    \"Support exportable structured outputs for downstream evaluation pipelines.\"\n",
        "]\n",
        "scope = [\n",
        "    \"Log parsing: timestamp, level, message extraction.\",\n",
        "    \"Regex detection for critical patterns (errors, warnings, auth failures).\",\n",
        "    \"Security detection: failed login, brute force, invalid token, SQL injection.\",\n",
        "    \"Incident scoring (low/medium/high).\",\n",
        "    \"CLI tool for file-based analysis.\",\n",
        "    \"Unit tests ensuring accuracy of detection rules.\"\n",
        "]\n",
        "non_scope = [\n",
        "    \"Full SIEM or monitoring platform.\",\n",
        "    \"Machine-learning anomaly detection.\",\n",
        "    \"Real-time dashboards or alert infrastructure.\",\n",
        "    \"Cloud-scale ingestion pipelines.\"\n",
        "]\n",
        "timeline = {\n",
        "    \"Day_1_2\": [\"Define regex rules\", \"Design parser architecture\"],\n",
        "    \"Day_3_4\": [\"Implement Log Analyzer\", \"Develop Incident Detector\"],\n",
        "    \"Day_5\": [\"Add CLI interface\", \"Add exports (JSONL)\", \"Write tests\"],\n",
        "    \"Day_6\": [\"Refine scoring rules\", \"Add documentation\"],\n",
        "    \"Day_7\": [\"Finalize repository\", \"Record demonstration\"]\n",
        "}\n",
        "stakeholders = {\n",
        "    \"owner\": \"You\",\n",
        "    \"developer\": \"You\",\n",
        "    \"reviewers\": [\"Safety Engineers\", \"Evaluation Analysts\"],\n",
        "    \"end_users\": [\"AI Safety Teams\", \"LLM Evaluation Analysts\"]\n",
        "}\n",
        "risks = [\n",
        "    {\n",
        "        \"risk\": \"Overly strict or loose regex patterns\",\n",
        "        \"impact\": \"Medium\",\n",
        "        \"mitigation\": \"Iterate using real log samples and refine rules.\"\n",
        "    },\n",
        "    {\n",
        "        \"risk\": \"Slow performance on large files\",\n",
        "        \"impact\": \"Low\",\n",
        "        \"mitigation\": \"Use streaming processing for scalability.\"\n",
        "    },\n",
        "    {\n",
        "        \"risk\": \"False positives in incident scoring\",\n",
        "        \"impact\": \"High\",\n",
        "        \"mitigation\": \"Expand test coverage with edge-case logs.\"\n",
        "    }\n",
        "]\n",
        "deliverables = [\n",
        "    \"Core modules: log_analyzer.py, incident_detector.py\",\n",
        "    \"Regex rules configuration file\",\n",
        "    \"CLI tool: logscan\",\n",
        "    \"Unit tests\",\n",
        "    \"Sample datasets\",\n",
        "    \"Documentation and usage examples\"\n",
        "]\n",
        "# -----------------------------------------\n",
        "# 2) Combine Charter\n",
        "# -----------------------------------------\n",
        "charter = {\n",
        "    \"title\": \"MP1: Log Analyzer + Incident Detector\",\n",
        "    \"overview\": (\n",
        "        \"A structured log-analysis and incident-detection tool that extracts events, \"\n",
        "        \"classifies severity, and identifies anomalies for AI safety evaluation workflows.\"\n",
        "    ),\n",
        "    \"goals\": goals,\n",
        "    \"scope\": scope,\n",
        "    \"non_scope\": non_scope,\n",
        "    \"timeline\": timeline,\n",
        "    \"stakeholders\": stakeholders,\n",
        "    \"risks\": risks,\n",
        "    \"deliverables\": deliverables\n",
        "}\n",
        "# -----------------------------------------\n",
        "# 3) Export as JSON\n",
        "# -----------------------------------------\n",
        "with open(\"mp1_project_charter.json\", \"w\") as f:\n",
        "    json.dump(charter, f, indent=4)\n",
        "# -----------------------------------------\n",
        "# 4) Pretty Print Output\n",
        "# -----------------------------------------\n",
        "pprint(charter)"
      ]
    }
  ]
}